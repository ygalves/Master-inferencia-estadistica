---
title: "Desafio1"
---

<img src="https://www.uao.edu.co/wp-content/uploads/2024/12/uao-logo-2-04.webp" width="15%"/>

# ------------------------------
<h2>UNIVERSIDAD AUTÓNOMA DE OCCIDENTE</strong></h2>
<h3>02/22/2025 CALI - COLOMBIA</strong></h3>


<h3><strong>MAESTRIA EN INTELIGENCIA ARTIFICIAL Y CIENCIA DE DATOS</strong></h3>
<h3><strong>INFERENCIA ESTADISTICA</strong></h3>
<h3><strong>ENTREGA: </strong> DESAFÍO 1</h3>
<h4>
<li><strong>Profesor:</strong> Cristian E García</li>
<li><strong>Alumno:</strong> Yoniliman Galvis Aguirre</li>
<li><strong>Código:</strong> 22500214</li>

</h4>

# ------------------------------
# Preparar el Sistema

Es necesario actualizar ó instalar Algunas librerias en RStudio, debido a que teste trabajo fúe realizado usando Linux Ubuntu 22.04, se presentaron algunos Issues que se solucionaron borrando algunos archivos de librerías, reinstalandolos y tomado desiciones al instalar el paquete dplyr el cual es un compendio de librerías y algunas de ellas estan usando funciones que comparten un nombre comun y con lo cual se genera fallas al tratar de cargarlas en el sistema.


```{r instalar_librerias}
# Variable de control para habilitar o deshabilitar la eliminación de archivos, si tiene problemas para instalar un paqute puede que ayude borrar estos archivos , primero ejecuta este Chunk en FALSE, si hay problemas llevalo a TRUE y ejecuta este Chunk de nuevo. ES probable que tenga que instalar las siguientes dependencias uasndo los siguientes comandos en uan terminal: 
# sudo apt-get update
# sudo apt-get install libharfbuzz-dev libfribidi-dev libcurl4-openssl-dev libssl-dev libxml2-dev libfontconfig1-dev libfreetype6-dev libpng-dev libtiff5-dev libjpeg-dev

eliminar_archivos_habilitado <- FALSE

# Definir los archivos a eliminar
archivos <- c(".Rhistory", ".RData", ".Rprofile")

# Función para eliminar los archivos si existen
eliminar_archivos <- function(archivos) {
  for (archivo in archivos) {
    if (file.exists(archivo)) {
      file.remove(archivo)
      cat("Archivo eliminado:", archivo, "\n")
    } else {
      cat("Archivo no encontrado:", archivo, "\n")
    }
  }
}

# Eliminar los archivos si se habilitó la opción
if (eliminar_archivos_habilitado) {
  eliminar_archivos(archivos)
} else {
  cat("La eliminación de archivos está deshabilitada.\n")
}

# Instalar y cargar el paquete para manejo de conflictos
install.packages("conflicted")
library(conflicted)

# Preferir funciones específicas de paquetes que estan en conflicto en la librería tidyverse purrr y tidyr las cuales tienen funciones con nombres iguales "stats" y "caret". así que vamos adefinir cual de estas funciones vamos a preferir

conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")
conflict_prefer("lift", "purrr")

# Para hacer isntalacion de varios paquetes creamos un vector que contenga los nombre de los paquetes que queremos instalar
paquetes <- c("dplyr", "ggplot2", "caret", "ModelMetrics", "stats4", "tidyverse","tidyr","gridExtra")

# hacemos una Función que nos permite instalar paquetes si no están ya instalados en el sistema
instalar_paquetes <- function(paquetes) {
  paquetes_instalados <- paquetes[paquetes %in% installed.packages()[,"Package"]]
  nuevos_paquetes <- paquetes[!(paquetes %in% installed.packages()[,"Package"])]
  
  if(length(nuevos_paquetes)) {
    install.packages(nuevos_paquetes, quiet = TRUE)
    cat("Se instalaron los siguientes paquetes:", nuevos_paquetes, "\n")
  } else {
    cat("Todos los paquetes ya están instalados.\n")
  }
  
  if(length(paquetes_instalados)) {
    cat("Los siguientes paquetes ya estaban instalados:", paquetes_instalados, "\n")
  }
}

# Instala los paquetes que son necesarios
instalar_paquetes(paquetes)


# Cargar los paquetes
library(dplyr)
library(ggplot2)
library(caret)
library(ModelMetrics)
library(stats4)
library(tidyverse)
library(tidyr)

```
# ------------------------------
# SITUACIÓN 1

Para estimar la proporción desconocida $π(0 < π ≤ 0,50)$ de una determinada especie de peces que habita en el océano Pacífico, se aplicará el siguiente plan de muestreo. Cada uno de $n( > 1)$ barcos pesqueros capturará peces hasta capturar exactamente $k( > 1)$ peces de la especie particular de interés, y se registrará el número total de peces capturados por cada barco pesquero. Todos los peces capturados se devolverán ilesos al océano Pacífico. Para resolver dicho problema se le pide investigar 4 formas diferentes de estimar dicha proporción y comparar el desempeño de los resultados.

Plantee tres escenarios diferentes para llevar a cabo dichas estimaciones, compare para diferentes tamaños de muestra y concluya teniendo en cuenta las medidas de desempeño como el ECM


## Entendiendo el Problema

*   En el plan de muestreo se capturará peces de forma aleatoria, cada captura tiene sólo dos posibles resultados, el pez capturado puede ser o no de la especie de interés, por tanto se obseva que el muestreo tiene un comportamiento binomial, el éxito de cada captura tiene una probabilidad $\pi$ y el fracaso $(1−\pi)$. En estadística se llama a este tipo de muestreos como Ensayo de Bernoulli^[https://es.wikipedia.org/wiki/Ensayo_de_Bernoulli︎].

*   Cada barco en el plan de muestreo va ha capturar peces hasta que se completen $k(>1)$
 éxitos o sea numero de peces de la especie que nos interesa, mientras no se alcance ese numero de éxitos, cada barco debe repetir el ensayo de bernoulli hasta completar la meta establecida.
 
*   El número total de muestras ó capturas necesarias para cumplir con los exitos solicitados es una variable aleatoria desconocida $X$.

*   Según la **teoría de la probabilidad^[https://www.eurekando.org/biografias/biografia-de-daniel-bernoulli-teoria-de-la-probabilidad/]**, el número de ensayos necesarios para conseguír $k$
 exitos en ensayos independientes de Bernoulli y con una probabilidad de éxito que permanece constantesigue una **Distribución negativa Binomial^[https://es.statisticseasily.com/glosario/%C2%BFQu%C3%A9-es-la-distribuci%C3%B3n-binomial-negativa%3F/#]**
 
La funcion de probilidad pra la distibución negativa binomial es:
$$P(X=x) = \binom{k-1}{x-1} \pi^k (1-\pi)^{x-k}, \; x = k, k+1, k+2, \ldots$$
Ya que para el $x−ésima$ captura sea el especimen $k−ésimo$ correctO, teniendo que $k−1$  éxitos en los $x−1$ capturas previas y luego una captura correcta en el $x−ésima$ captura

**Dónde:**

$$Esperanza=\mathbb{E}[X]=\frac{k}{\pi}$$

$$Varianza=Var(X)=\frac{k(1−\pi)}{\pi²}$$

*   Es necesario definir el valor real de la proporción de  peces en el oceano de la especie buscada ($\pi$) y a este se le denominará como $\pi_{verdadero}$, ese valor que ya se conoce como correcto nos va ha permitir comparar los estimadores en la simulaciones ó en los diferentes escenarios propuestos y luego comparar los resultados con el valor real para saber la precisión y consistencia de los diferentes estimadores.

*   Si no conocemos a $\pi_{verdadero}$ y es lo que realmente sucede en la vida real, para las simulaciones establecemos el valor a un estimado para poder realizar los análisis necesarios a los estimadores o en su defecto se evaluan los estimadores usando tecnicas diferentes a ECM tal como usar la varianza, usar los intervalos de confianza, estudios de remuestreo, etc.

*   Los estudios de simulacion donde se estima a$\pi_{verdadero}$ nos permiten evaluar el comportamiento de los estimadores bajo condiciones controladas para verificar la fiabilidad y robustez para poder elegir un método apropiado para aplicarlo despues a los datos reales y evitar fallas posteriores.

*   Debemos usar un prior que es básicamente la distribucion de probabilidad que tenemos antes de realizar la observacion de datos, o sea es básicamente una estiamción de la probailidad que esperamos del muestreo antes de que se realice y se analisen los datos. 

*   El Prior es fundamental para el teorema de bayes donde se combina con la función de verosimilitud para obtener la distribucion posterior:
$$Teorema\;de\;Bayes = Posterior\; \alpha\; Verosimilitud\; x\; Prior$$

En este ejercicio, creemos que la proporción está entre 0 y 0.5 y no se inclina a favor de ningun valor particular y podemos utilizar un prior uniforme en intervalo $(0, 0.5)$ y de esta forma inicialmente consideramos que todos los valores en ese rango son probables.


## Solución

Propongo cuatro estimadores para $\pi$:

1.    Estimador MLE, de la mediana muestral ó Momentos: 
$\hat{\pi}_{MLE} = \frac{k}{\overline{X}}$

2.    Estimador basado en transformación logarítmica: 
$\hat{\pi}_{log} = exp\left\{ 
\begin{array}{l}
\frac{1}{n}\sum_{i = 1}^{n} ln \frac{k}{X_i}
\end{array}
\right\}$

3.    Estimador de Bayes ó bayesiano: asumiremos que es probable cualquier valor de $\pi$

4.    Estimador insesgado de varianza mínima - (Uniformly Minimum-Variance Unbiased Estimator):
$\hat{\pi}_{UMVUE} = \frac{nk-1}{\sum_{i = 1}^{n} X_i-1}$


```{r Solucion}
# Estimacion de la proporcion de peces en el oceano pacífico
## Definimos los parámetros para hacer la simulacion
set.seed(1234)

# pi_verdadero es el valor real del parámetro que queremos estimar, en este caso es la proporcion de la especie de peces en el oceano pacífico $\pi$, contra este valor es que vamos a comparar los estimadores en la simulación, sin este valor no podriamos hacer la validacion del ECM ó del sesgo de la simulación. Si no se conoce el valor pi_verdadero, no es posible usar ECM y tocaría evaluar el rendimiento con otras métricas como varianza, intervalos de confianza o por estudios previos de muestreo.
pi_verdadero <- 0.3  # Valor verdadero de π (0 < π ≤ 0.5)

# Definimos los 3 escenarios: n = número de barcos, k = número de capturas requeridas
Escenarios <- list("Escenario 1" = list(n = 10, k = 5),
                   "Escenario 2" = list(n = 20, k = 9),
                   "Escenario 3" = list(n = 50, k = 20))

B <- 5000  # Número de simulaciones por escenario

# --- Función para el Estimador Bayesiano ó Prior---
# Calcula la media del posterior con prior uniforme en (0, 0.5)
media <- function(sum_x, n, k) {
  post_density <- function(pi) {
    2 * pi^(n * k) * (1 - pi)^(sum_x - n * k)
  }
  norm_const <- integrate(post_density, lower = 0, upper = 0.5)$value
  num_int <- integrate(function(pi) pi * post_density(pi),
                         lower = 0, upper = 0.5)$value
  return(num_int / norm_const)
}

# --- Definición de los Estimadores Propuestos ---

# 1. Estimador MLE (o basado en la media muestral)
estimador_mle <- function(data, k) { 
  k / mean(data) 
}

# 2. Estimador basado en transformación logarítmica
# Evitamos usar el nombre "log" para no colisionar con la función base.
estimador_log <- function(data, k) { 
  exp(mean(log(k / data))) 
}

# 3. Estimador Bayesiano
estimador_bayes <- function(data, k) { 
  media(sum(data), length(data), k) 
}

# 4. Estimador UMVUE (insesgado)
estimador_umvue <- function(data, k) {
  (length(data) * k - 1) / (sum(data) - 1)
}

# --- Simulaciones y Comparaciones ---
result <- list()           # Para almacenar el ECM de cada estimador por escenario
estimates_all <- data.frame()  # Para recolectar los valores estimados y graficarlos

for (esc in names(Escenarios)) {
  n <- Escenarios[[esc]]$n
  k <- Escenarios[[esc]]$k
  
  # Matriz para almacenar los valores de cada estimador en cada simulación
  est <- matrix(NA, nrow = B, ncol = 4)
  colnames(est) <- c("MLE", "Logaritmo", "Bayes", "UMVUE")
  
  for (i in 1:B) {
    # Generar datos para n barcos:
    # rnbinom(n, size = k, prob = pi_verdadero) genera el número de fracasos hasta k éxitos.
    # Sumamos k para obtener el total de capturas.
    data <- rnbinom(n, size = k, prob = pi_verdadero) + k
    
    # Calcular cada uno de los estimadores:
    est[i, "MLE"]       <- estimador_mle(data, k)
    est[i, "Logaritmo"] <- estimador_log(data, k)
    est[i, "Bayes"]     <- estimador_bayes(data, k)
    est[i, "UMVUE"]     <- estimador_umvue(data, k)
  }
  
  # Calcular el ECM para cada estimador en el escenario actual
  ECM <- colMeans((est - pi_verdadero)^2)
  result[[esc]] <- ECM
  
  # Convertir a formato largo para graficar
  df <- as.data.frame(est)  # Se usa "est" (no "estimaciones")
  df$Simulacion <- 1:B
  df_long <- pivot_longer(df, cols = c("MLE", "Logaritmo", "Bayes", "UMVUE"),
                          names_to = "Estimador", values_to = "Valor")
  df_long$Escenario <- esc
  estimates_all <- rbind(estimates_all, df_long)
}

# Mostrar los resultados (ECM) para cada escenario
for (esc in names(result)) {
  cat("\nEscenario", esc, "\n")
  print(result[[esc]])
}

# --- Graficar la PMF teórica de la distribución negativa binomial para cada escenario ---
# Esto ilustra la distribución de capturas en un solo barco (para cada k del escenario)
for (esc in names(Escenarios)) {
  k_vis <- Escenarios[[esc]]$k
  x_vals <- k_vis:(k_vis + 40)

  # Redondeamos para asegurarnos de tener valores enteros en la función dnbinom

  pmf_vals <- dnbinom(round(x_vals - k_vis), size = k_vis, prob = pi_verdadero)
  df_teorico <- data.frame(Total = x_vals, Probabilidad = pmf_vals)
  
  set.seed(123)  # Para reproducibilidad
  n_sim <- 10000
  simulados <- rnbinom(n_sim, size = k_vis, prob = pi_verdadero) + k_vis
  df_sim <- data.frame(Total = simulados)
  
  g <- ggplot(df_teorico, aes(x = Total, y = Probabilidad)) +
    geom_bar(stat = "identity", fill = "skyblue", color = "black") +
    geom_line(data = df_teorico, aes(x = Total, y = Probabilidad),
              color = "red", linewidth = 1) +
    labs(title = paste("PMF Teórica - Escenario", esc, "(k =", k_vis, ", π =", pi_verdadero, ")"),
         x = "Número Total de Peces Capturados", y = "Probabilidad") +
    xlim(c(k_vis, k_vis + 40)) +
    theme_minimal()
  print(g)
}

# Construir la tabla ECM utilizando sapply y verificando que cada estimador exista
ECM_tabla <- data.frame(
  Escenario   = names(result),
  n           = sapply(names(result), function(x) Escenarios[[x]]$n),
  k           = sapply(names(result), function(x) Escenarios[[x]]$k),
  MLE         = sapply(result, function(x) { if("MLE" %in% names(x)) as.numeric(x["MLE"]) else NA }),
  Logaritmo   = sapply(result, function(x) { if("Logaritmo" %in% names(x)) as.numeric(x["Logaritmo"]) else NA }),
  Bayes       = sapply(result, function(x) { if("Bayes" %in% names(x)) as.numeric(x["Bayes"]) else NA }),
  UMVUE       = sapply(result, function(x) { if("UMVUE" %in% names(x)) as.numeric(x["UMVUE"]) else NA }),
  stringsAsFactors = FALSE
)


# Resumen de EMC de el desempeño de los estimadores en cada escenario planteado
if(requireNamespace("knitr", quietly = TRUE)){
  knitr::kable(ECM_tabla, caption = "ECM de cada estimador por escenario, donde n = número de barcos, k = número de capturas requeridas")
} else {
  print(ECM_tabla)
}

```

## Conclusiones

En el ejercicio propuse 4 etimadores: el de mediana muestral o momentos (MLE) y su version insesgada UMVUE o de varianza mínima, el de transformación Logaritmica y el Bayesiano.

Se plantearon 3 escenarios diferentes y se realizáron las simulaciones respectivas.
Obsevamos que segun el ECM:

*   Los estimadores basados en la media muestral (MLE y UMVUE) son los de mejor desempeño.

*   Los estimadores basados en la media muestral (MLE y UMVUE) se comportan de manera muy similar.

*   Los estimadores basados en la media muestral (MLE y UMVUE) mejoran en consistencia a medida que las muesras $k$ aumentan.

*   El estimador basado en transformación logarítmica mejora igual a medida que las muestras sonmas grandes pero mantiene un ECM superior y eso significa menor eficiencia.

*   El estimador bayesiano no presenta resultados en todos los escenarios y puede signiicar que necesita mayor verificacion o una seleccion del pior nueva o que este estimador no es suficientemente robusto para este muestreo en particular.


# ------------------------------
# SITUACIÓN 2

Suponga que se tiene una muestra aleatoria de tamaño $2n$ tomada de una población $X$, con $E(X) = \mu$ y $Var(X) = \sigma²$, Sean:

$$\overline{X}_1 = \frac{1}{2n} \sum_{i=1}^{2n}x_i\quad \text{y}\quad \overline{X}_2 = \frac{1}{n} \sum_{i=1}^{n}x_i$$
dos estimadores de $\mu$.

*   ¿Cuál es le mejor estimador de $\mu$?

*   Simule una situación con 1000 muestras de tal forma que se pueda evidenciar de manera gráfica cual de los dos estimados es mejor.

## Entendiendo el Problema

*   Tenemos una poblacion $X$ la cual tiene una media dad por la funcion $E(X)=\mu$ y una varianza $Var(X)=\sigma²$.
*   Como el ejercicio no hace mencion a la distribución de esta población $X$, asumimos una distribucion normal^[https://economipedia.com/definiciones/teorema-central-del-limite.html].
*   De dicha población vamos a extraer una muestra aleatória cuyo tamaño es $2n$.
*   De esta muestra consideramos dos estimadores para calcular la media $\mu$:
    1.  El primer estimador de $\overline{X}_1$ el cual va ha utilizar todos los datos de la muestra ($2n$ datos):
        $$\overline{X}_1 = \frac{1}{2n} \sum_{i=1}^{2n}x_i$$
    2.  El segundo estimador de $\overline{X}_2$ el cual va ha utilizar sólo los datos de la primera mitad de la muestra ($n$ datos):
        $$\overline{X}_2 = \frac{1}{n} \sum_{i=1}^{n}x_i$$
*   Tenemos que determinar cual es el mejor estimador de $\mu$
    1.  Ambos estimadores son insesgados ya que: $E(\overline{X}_1) \; = \; E(\overline{X}_2 ) \; = \; \mu$.
    2.  Vamos a medir el desepeño usando la varanza de cada uno de los dos estimadores, donde la Varianza de $\overline{X}_1$ es: $Var(\overline{X}_1)=\frac{\sigma²}{2n}$ y la Varianza de $\overline{X}_2$ es:   $Var(\overline{X}_2)=\frac{\sigma²}{n}$
    3.  Podemos estimar entonces por observación del divisor que el estimador de $Var(\overline{X}_1)$ es menor y entonces debe ser mas preciso, y por tanto debe de tener menor varianza, entonces **el estimador $\overline{X}_1$ es el mejor estimador de $\mu$**.
    
```{r}
###############################################################################
# Estimación de la Media de una Población
# Comparación de dos estimadores:
#   X1 = (1/(2n)) * Σ x_i (usa 2n datos)
#   X2 = (1/n)  * Σ x_i (usa solo los primeros n datos)
#
# Se evidenciará que X1 es mejor ya que tiene menor varianza.
###############################################################################

# Cargar las librerías necesarias
library(ggplot2)
library(knitr)

# Parámetros de la simulación
set.seed(123)                # La semilla para grantizar la reproducibilidad
n <- 50                      # tamaño de la muestra
N <- 2 * n                   # Tamaño total de la muestra
mu <- 10                     # Media de la poblacion
sigma <- 2                   # Desviación estándarde la poblacion
replicaciones <- 1000        # Número de muestras para la simulacion

# Creamos los vectores para almacenar los estimadores
X1 <- numeric(replicaciones) # Estimador que usa 2n datos (todos)
X2 <- X1  # Estimador que solo usa el primer set de datos

# Simulación: en cada réplica se extrae una muestra de tamaño 2n de la población
for(i in 1:replicaciones){
  sample_data <- rnorm(N, mean = mu, sd = sigma)
  X1[i] <- mean(sample_data)        # Usa todos los 2n datos
  X2[i] <- mean(sample_data[1:n])     # Usa solo los primeros n datos
}

# Calcular las varianzas empíricas (ECM, pues son insesgados)
ecm_X1 <- var(X1)   # Teóricamente: sigma^2/(2n) = (4)/(100) = 0.04
ecm_X2 <- var(X2)   # Teóricamente: sigma^2/n   = (4)/(50)  = 0.08

cat("Varianza (ECM) de X1 (2n datos):", ecm_X1, "\n")
cat("Varianza (ECM) de X2 (n datos):", ecm_X2, "\n")

# Crear un data frame para graficar las densidades de ambos estimadores
df <- data.frame(
  Estimador = factor(c(rep("X1 (2n datos)", length(X1)), rep("X2 (n datos)", length(X2)))),
  Valor = c(X1, X2)
)

# Gráfica comparativa: densidades de los estimadores y línea vertical en mu
g <- ggplot(df, aes(x = Valor, fill = Estimador)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = mu, linetype = "dashed", color = "black", linewidth = 1) +
  labs(title = "Comparación de Estimadores de la Media",
       subtitle = "X1: usa 2n datos vs. X2: usa n datos",
       x = "Valor estimado de μ", y = "Densidad") +
  scale_fill_manual(values = c("blue", "red")) +
  theme_minimal()

print(g)

# Tabla de resumen usando knitr::kable
ECM_tabla <- data.frame(
  Estimador = c("X1 (2n datos)", "X2 (n datos)"),
  ECM = c(ecm_X1, ecm_X2)
)

# Imprimir la tabla
kable(ECM_tabla, caption = "ECM (Varianza empírica) de cada estimador")

```
## Conclusiones

*   El análisis en la gráfica y la teoría nos demuestra que el mejor estimador de $\mu$ es $\overline{X}_1$ ya que este utiliza los $2n$ datos y presenta una varianza $\frac{\sigma²}{(2n)}$ y esa es menor que la varianza de $\overline{X}_2 = \frac{\sigma²}{(n)}$, porque esta solo utiliza la primera mitad de lso datos $n$.
*   Se demuestra entonces de forma teórica y de forma gráfica que ql estimador de mejor desempeño será siempre aquel que utiliza toda la muestra de datos y no solo una parte de ella.

# ------------------------------
# SITUACIÓN 3

En una población hay un número $\theta$ de vehículos informales (llamados “piratas”), que es desconocido. Supongamos que los piratas, están numerados visiblemente en forma consecutiva: $1,2,3,...,\theta$. Con el propósito de estimar $\theta$ , usted registra una muestra aleatoria de $n$ piratas y anotando cada vez el número $X$ correspondiente. Así dispone de una muestra aleatoria: $X1, X2…, Xn$. Existen varias propuestas razonables de estimadores para el número total $\theta$ de taxis, como las que se describen a continuación y que surgen de la consideración de que la distribución de la variable aleatoria $X$ (número del carro), es uniforme discreta. Los estimadores propuestos son los siguientes:

$$\hat{\theta}_{(1)} = 2\overline{X}_n-1$$
$$\hat{\theta}_{(2)} = X_{(n)}+X_{(1)}-1$$
$$\hat{\theta}_{(3)} = X_{max}+\overline{d}$$
Donde $\overline{d}$ es la media de los saltos consecutivos de los números de la muestra al ser ordenados en forma creciente. (Desarrolle $\overline{d}$ y se simplificará la expresión)

$$\hat{\theta}_{(4)} = 2Me(X)-1$$
$$\hat{\theta}_{(5)} = \overline{X}+3S$$
Simule el comportamiento de cada uno de estos estimadores, $R$ o cualquier otra opción tecnológica, variando el valor del parámetro y el tamaño de muestra $n$ . Nos interesa compararlos especialmente en cuanto al Sesgo, la Varianza de los estimadores y también el Error Cuadrático Medio (ECM) y cualquier otro indicador que le parezca razonable.

## Entendiendo el Problema

*   Dada una población de vehiculos tenemos una cantidad desconocida $\theta$ de vehiculos que hacen acarreo de personas de forma informal ("piratas").
*   Asumimos que los vehiculos estan marcados con numeros consecutivos así: $1, 2, 3, \dots, \theta$.
*   Asumimos que si extraemos una muestra aleatória de $\theta$ seguirá una **distribución uniforme discreta^[https://es.wikipedia.org/wiki/Distribuci%C3%B3n_uniforme_discreta]** sobre el conjunto $\left\{1,2 \dots,\theta\right\}$. Esto porque:
    1.  Los vehículos estan numerados de forma consecutiva $1,2,3, \dots, \theta$. Con lo cual cada número entre $1$ y $\theta$ aparece solo una vez.
    2.  Todos los vehículos en la población de interés tiene la misma probabilidad de ser seleccionado al tomar una muestra aleatória, como la numeración es consecutiva y cada número es único, la probabilidad de tomar cualquier número $x$ con $\left(1\leq x \leq \theta\right)$ igual para todos los sujetos y sin favorecer a ninguno, o sea $P(X = x) = \frac{1}{\theta}\quad para \; todo \; x \; en \left\{1,2, \dots,\theta\right\}$
    3.  **distribución uniforme discreta - $U(a,b)$** es aquella en la que cada uno de los valores posibles tienen la misma probabilodad de ocurrir.
    4.  Tomando las estimaciones dadas en el ejercicio podemos derivar fórmulas basadas en las propiedades de la distribución uniforme directa, por ejemplo la media teórica de la distribución uniforme discreta es: $E(X)= \frac{\theta + 1}{2}$, con esta funcion podemos fromular el estimador $\hat{\theta}_{(1)} = 2\overline{X}_n-1$.
*   Como $\theta$ es desconocido vamos a estimarlo tomando una muestra aleatória de $n$ vehículos y se llevan apuntes de sus números $X_1, X_2, \dots , X_n$.
*   Hay que tener en cuenta que $\theta$ es el valor límite superior de la población de vehiculos informales, que es desconocido, la probabilidad de encontrarlo ó acercarnos a este, tomando sólo una muestra de esta población es baja si $n << \theta$
*   Para el estimador $\hat\theta_{(1)}$ usamos la media muestral $\overline{X}_n$ ya que la media de una distribución uniforme discreta en ${1, \dots, \theta}$ es $\frac{\theta + 1}{2}$ y se puede despejar para $\theta$.

```{r}
###############################################################################
# Estimación de θ (número total de vehículos piratas)
#
# La población consiste en vehículos numerados consecutivamente: 1,2,...,θ.
# Se extrae una muestra aleatoria de tamaño n (sin reemplazo) y se registran los
# números observados: X1, X2, …, Xn.
#
# Se proponen los siguientes estimadores:
#
#   (1)   θ̂(1) = 2·X̄ - 1
#          (porque E(X) = (θ+1)/2 para X ~ Uniforme{1, …, θ})
#
#   (2)   θ̂(2) = X_(n) + X_(1) - 1
#
#   (3)   θ̂(3) = X_max + d̄, donde d̄ es la media de los saltos consecutivos.
#          Al ordenar la muestra: d̄ = (X_(n) - X_(1))/(n-1), de modo que
#          θ̂(3) = X_(n) + (X_(n) - X_(1))/(n-1)
#
#   (4)   θ̂(4) = 2·Med(X) - 1
#
#   (5)   θ̂(5) = X̄ + 3·S
#
# Se simula el comportamiento de estos estimadores para diferentes escenarios
# variando el valor real de θ y el tamaño de muestra n.
###############################################################################

# Cargar las librerías necesarias
library(ggplot2)
library(dplyr)
library(tidyr)
library(knitr)
library(gridExtra)

# Parámetros de simulación
set.seed(1234)
theta_true <- 200    # Valor real de θ (número total de vehículos)
n <- 10              # Tamaño de la muestra (n vehículos observados)
B <- 5000            # Número de réplicas de la simulación

# Inicializamos vectores para almacenar los valores de cada estimador
est1 <- numeric(B)   # Estimador (1): 2*mean - 1
est2 <- numeric(B)   # Estimador (2): min + max - 1
est3 <- numeric(B)   # Estimador (3): max + (max - min)/(n-1)
est4 <- numeric(B)   # Estimador (4): 2*median - 1
est5 <- numeric(B)   # Estimador (5): mean + 3*sd

# Simulación: Para cada réplica se extrae una muestra aleatoria de tamaño n de {1,2,...,θ}
for (i in 1:B) {
  muestra <- sample(1:theta_true, size = n, replace = FALSE)
  
  # Calcular cada uno de los estimadores:
  est1[i] <- 2 * mean(muestra) - 1
  est2[i] <- min(muestra) + max(muestra) - 1
  est3[i] <- max(muestra) + (max(muestra) - min(muestra)) / (n - 1)
  est4[i] <- 2 * median(muestra) - 1
  est5[i] <- mean(muestra) + 3 * sd(muestra)
}

# Crear un data frame con los resultados de las simulaciones y convertir a formato largo
df <- data.frame(
  Replication = 1:B,
  `θ1` = est1,
  `θ2` = est2,
  `θ3` = est3,
  `θ4` = est4,
  `θ5` = est5
)


df_long <- pivot_longer(df, cols = -Replication, 
                        names_to = "Estimator", values_to = "Value")
# Convertir la variable Estimator a factor (usando los valores observados)
df_long$Estimator <- as.factor(df_long$Estimator)

# Graficar las densidades de cada estimador (facetas) con la línea vertical en θ_true
p_dens <- ggplot(df_long, aes(x = Value, fill = Estimator)) +
  geom_density(alpha = 0.5) +
  facet_wrap(~ Estimator, scales = "free") +
  geom_vline(xintercept = theta_true, linetype = "dashed", color = "black", linewidth = 1) +
  labs(title = "Distribución de los Estimadores para θ",
       subtitle = paste("θ verdadero =", theta_true, "| Tamaño de muestra n =", n),
       x = "Valor estimado de θ", y = "Densidad") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set2")
print(p_dens)

# Calcular sesgo, varianza y ECM para cada estimador y construir una tabla resumen
summary_table <- df_long %>%
  group_by(Estimator) %>%
  summarise(
    Bias = round(mean(Value) - theta_true, 3),
    Variance = round(var(Value), 3),
    ECM = round((mean(Value) - theta_true)^2 + var(Value), 3)
  )

# Imprimir la tabla resumen con knitr::kable
kable(summary_table, digits = 3, caption = "Resumen de los Estimadores: Sesgo, Varianza y ECM")

# Graficar barras comparativas para Bias (valor absoluto), Varianza y ECM
p_bias <- ggplot(summary_table, aes(x = Estimator, y = abs(Bias), fill = Estimator)) +
  geom_bar(stat = "identity") +
  labs(title = "Bias Absoluto de cada Estimador", y = "Bias Absoluto", x = "Estimador") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set2")

p_variance <- ggplot(summary_table, aes(x = Estimator, y = Variance, fill = Estimator)) +
  geom_bar(stat = "identity") +
  labs(title = "Varianza de cada Estimador", y = "Varianza", x = "Estimador") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set2")

p_ecm <- ggplot(summary_table, aes(x = Estimator, y = ECM, fill = Estimator)) +
  geom_bar(stat = "identity") +
  labs(title = "ECM de cada Estimador", y = "ECM", x = "Estimador") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set2")

# Combinar las tres gráficas en un panel vertical
grid.arrange(p_bias, p_variance, p_ecm, ncol = 1)


```

## Conclusiones
  *   El indicador $\theta_4$ presenta un sesgo cercano a cero $(0.04)$ lo cual es el ideal pero la varianza es la mas alta de todos $(2856.68)$ y nos indica que los valores estimados tienen variaciones altas entre una muestra y la otra.
  *   El indicador $\theta_5$ presenta el sesgo mas elevado $(71.79)$ y una varianza alta $(1064.25)$ aunque la varianza está entre la media de todos el alto sesgo nos indica que no es un estimador muy adecuado para la implementacion.
  *   Los indicadores $\theta_1$ y $\theta_2$ presentan los sesgos mas bájos $(0.22)$ y $(0.23)$ respectivamente, pero la varianza de $\theta_1$ es alta $(1234.53)$ mientras la varianza de $\theta_2$ es moderada pero no es la mas baja de entre todos los indicadores $(562.23)$
  *   El indicador $\theta_3$ presenta un sesgo bajo y aunque no es el menor de todos los estimadores si es cercano a 0: $(1.08)$ además si tiene el valor de varianza mas bajo de todo el set $(306.33)$.
  *   El ECM es la sumatoria del cuadrado del sesgo y la varianza y refleja el desempeño o presicion global del estimador, tomando en cuenta esto el ECM más bajo es de $\theta_3$ con $(307.49)$ lo cual nos indica que a pesar de que el sesgo no es el mas bájo la combinacion de este y la poca varianza hacen este indicador como el mejor en precision global.
  *   Los estimadores $\theta_1, \theta_4 y \theta_5$ tiene ECMs muy altos $(1234.58, 2856.68, 6212.32)$ respectivamente y esto indica que no sin importar el bajo sesgo, la alta varianza los convierte en inadecuados.
  *   El estimador $\theta_2$ tiene igualmente un ECM bajo $(562.28)$, tiene tambien bajo sesgo $(0.23)$ y una varianza moderada $(562.23)$ pero el ECM es mayor que el ECM de $\theta_3$ con $(307.45)$, con lo cual concluimos que $\theta_2$ es un buen indicador.

La mejor estimación de $\theta$ se logra usando el estimador $\hat{\theta_3} = X_{max} + \frac{X_{max} -X_{min}}{n-1}$, esto a que este presenta la mejor precision global $(307.49)$ manteniendo un sesgo cercano a cero $(1.08)$ y la varianza mas baja $(306.33)$, ahora bien este desafio necesita estimar un valor desconocido de $\theta$ por tanto una baja varianza nos ayuda a estimar un valor que sea mas cercano al valor real de $\theta$.

# ------------------------------
# SITUACIÓN 4

Tiempos de atención entre llamadas de reclamaciones por seguros.

Sean $(X_1, \dots, X_n)$ con densidad $\lambda e^{\lambda x},(x \geq 0),(n \leq2)$. Sea $S_n=\sum_{i=1}^{n} X_i)$. Es bien conocido que $Z = \lambda S_n$ tiene densidad:
$$f_z(z) = \frac{z^{n-1}e^{-z}}{(n-1)!},\;z \geq 0$$
*   Utilice esto para calcular el sesgo y el ECM de $\hat{\lambda}=\frac{n-1}{S_n}$.

*   Calcule el estimados de momentos y máximo verosímil para la función de densidad.

## Entendiendo el Problema

*   En un callcenter de una empresa de seguros, se necesita evaluar las propiedades de los estimadores de los tiempos de atención entre llamadas de reclamaciones para la densidad $f_z(z) = \frac{z^{n-1}e^{-z}}{(n-1)!},\;z \geq 0$
*   Utilizando la transformación $Z = \lambda S_n$ se necesita calcular teoricamente el sesgo y el ECM del estimador dado: $\hat{\lambda}=\frac{n-1}{S_n}$.
*   Se necesita calcular el estimador de momentos y el estimador de máxima verosimilitud para el ejercicio.
*   El ejercicio indica que cada $X_i$ tiene una densidad $f(x) = \lambda e^{\lambda x},(x \geq 0),$ y dado que el estimador propuesto $\hat{\lambda}=\frac{n-1}{S_n}$ y ya que el objetivo es estimar los tiempos muertos entre las llamadas al call center, podemos deducir que en este ejercicio los datos a evaluar se distinguen como una **Distribución exponencial^[https://mundoteca.org/distribuciones-exponenciales-y-sus-caracteristicas/]**
*   Para este análisis de este ejercicio vamos a utilizar las propiedades de la esperanza porque estamos iniciando desde que $S_n$ tiene una distribución Gamma y por eso es que $$E\left(\frac{1}{S_n}\right)=\frac{\lambda}{n-1},$$
Cuando despejemos esperamos demostrar que: $$E\left(\frac{n-1}{S_n}\right)=\lambda.$$
*   Al despejar usando la esperanza podremos comprobar que el estimador $\hat{\lambda}=\frac{n-1}{S_n}$ es insesgado y que permite derivar la varianza y el ECM usando las propiedades de la **distribucion Gamma**

### **Propiedades de la distribucion Gamma $(\Gamma)$^[https://es.wikipedia.org/wiki/Distribuci%C3%B3n_gamma]**

Las propiedades que voy a colocar acá permiten de forma general utilizar la distribución Gamma en diferentes aplicaciones, por ejemplo en el modelo de este ejercicio sobre tiempos de atención, análisis de superviciencia y en la suma de tiempos entre eventos en procesos $Poisson$.
La relación $E\left[\frac{1}{S_n}\right]\,=\,\frac{\lambda}{(n-1)}$ que es muy usado en los problemas de estimación se fundamenta en las propiedades de Gamma y en especial en el cálculo de momentos de la distribucion Gamma:

1.  **Función de Densidad de Probabilidad ó PDF**
    Si $X$ sigue una distribucion gamma con parámertrós forma $\alpha$ y tasa $\beta$ (a veces se usa la escala $\theta=\frac{1}{\beta}$ y se escribe: $$f(x,\alpha,\beta)=\frac{\beta^{\alpha}}{\Gamma(\alpha)}x^{\alpha-1}e^{-\beta x},\;x>0,$$
    Donde $\Gamma(\alpha)$ es la función Gamma definida por: $$\Gamma(\alpha)=\int_{0}^{\infty} t^{\alpha-1} e^{-t}\, dt$$
2.  **Función de Distribución acumulada ó CDF**
    la CDF se expresa en términos de la funcion de Gamma incompleta:$$F(x;\alpha,\beta)=\frac{1}{\Gamma(\alpha)}\gamma(\alpha,\beta x),$$
    dónde $\gamma(\alpha,\beta x)$ es la Gamma incompleta inferior.
3.    **Cálculo de Momentos**
    a.   La esperanza de X es: $$E\left[X\right]=\frac{\alpha}{\beta}.$$
    b.   La varianza es: $$Var(X) = \frac{\alpha}{\beta²}.$$
    c.   Momento inverso ó expectativa del inverso, esperanza inversa ó propiedad clásica, esta es el resultado derivado de la propiedad de los momentos y es la expecatativa del inverso de una variable Gamma, si $S\sim\Gamma(\alpha,\beta)\;y\;\alpha>1,$ se tiene que $$E\left(\frac{1}{S}\right)=\frac{\beta}{\alpha-1}.$$
4.    **Función Generadora de Momentos o MGF**
    La función generadora de momentos de $X$ está dad por: $$M_x(t)=\left(1-\frac{t}{\beta}\right)^{-\alpha},\; para \;t<\beta.$$
5. **Suma de Variables Gamma**
Una propiedad muy útil es la suma de variables Gamma independientes, estas omparten el mismo parámetro de tasa de $\beta$, también tiene una distribución Gamma, así: $$X_1\sim\,\Gamma(\alpha_1,\beta)\quad y \quad X_2 \sim \, Gamma(\alpha_2,\beta),$$
    entonces, pues tenemos que:$$X_1+X_2\,\sim\,\Gamma(\alpha_1+\alpha_2,\beta).$$
6.    **Relación con Otras Distribuciones**
    *   **Distribución Exponencial:**
        Si $\alpha=1,$ la distribución Gamma se reduce a la distribución exponencial con parámetro $\beta$.
    *   La distribución $X²$ con $\nu$ grados de libertad es un caso especial de la Gamma porque: $$\chi_{\nu}^{2}\,\sim\,\Gamma\left(\frac{\nu}{2},\frac{1}{2}\right).$$
7.    **Propiedad de Escalamiento**
  Si $X\,\Gamma(\alpha,\beta)\;y\;c>0,$ entonces la variable escalada $cX$ tiene distribución: $$cX\,\nu\,\Gamma\left(\alpha,\frac{\beta}{c}\right).$$
    
## Solución
1. **Para calcular el sesgo del estimador** $\hat{\lambda}=\frac{n-1}{S_n}$

Ya que la propiedad de el momento inverso (ver punto 3.c de las propiedades Gamma): $S\sim\Gamma(\alpha,\beta)\;y\;\alpha>1,$ y asumimos que $\alpha = n\;y\; \beta=\lambda)$, deducimos:

Bueno conociendo que para $S_n\,\sim\,\Gamma(n,\lambda)$, tenemos que la propiedad es:$$E(\frac{1}{S_n})=\frac{\lambda}{n-1}$$, asi que el valor esperado de el estimador es: $$E(\hat{\lambda})=E\left(\frac{n-1}{S_n}\right)=(n-1)E\left(\frac{1}{S_n}\right)=(n-1)\left(\frac{\lambda}{n-1}\right)=\lambda.$$

Por tanto, como $E(\hat{\lambda}) =\lambda$ podemos decir que el estimador $\hat{\lambda}$  es **insesgado**, porque el sesgo es la diferencia entre el valor esperado del estiamdor y el parámetro verdadero o sea: $$Sesgo=E(\hat{\lambda})-\lambda=0$$ y como el sesgo en este caso es 0, entonces se puede decir que no existe ó es insesgado.

2. **Eror cuadrático medio ó ECM**
Teniendo en cuenta que el $\hat{\lambda}$  es **insesgado**, entonces esperamos que $ECM = varianza$ y para obtener $Var(\hat{\lambda})$ tenemos que hallar la varianza de $\frac{1}{S_n}$ y sabemos que para $S_n\sim\Gamma(n,\lambda)\;\,n>2$ y usamos 2 para exista una varianza, entonces:$$*\qquad E\left(\frac{1}{S_n}\right)=\frac{\lambda}{n-1'}$$ $$*\qquad E\left(\frac{1}{S_{n}^{2}}\right)=\frac{\lambda²}{(n-1)(n-2)}$$ Ahora :
$$Var\left(\frac{1}{S_n}\right)=E\left(\frac{1}{S_{n}^{2}}\right)-\left[E\left(\frac{1}{S_n}\right)\right]²=\frac{\lambda²}{(n-1)(n-2)}-\left(\frac{\lambda}{n-1}\right)²$$
$$Var\left(\frac{1}{S_n}\right)=\frac{\lambda²}{(n-1)²}\left(\frac{n-1}{n-2}-1\right)=\frac{\lambda²}{(n-1)²}\left(\frac{(n-1)-(n-2)}{n-2}\right)=\frac{\lambda²}{(n-1)²(n-2)}.$$
Ahora como $\hat{\lambda}=(n-1)(\frac{1}{S_n})$, entonces tenemos:

$$Var(\hat{\lambda}) = (n-1)²Var\left(\frac{1}{S_n}\right)=(n-1)².\frac{\lambda²}{(n-1)²(n-2)}=\frac{\lambda²}{n-2}$$
Entonces como ya sabemos que ECM = Var tenemos que: $$ECM(\lambda²)=\frac{\lambda²}{n-2}$$

3. **Estimador por el Momento y máxima verosimilitud**
Ahora como el ejercicio es una distribución exponencial y $X\sim Exp(\lambda)$, tenemos que: $E\left[X\right]= \frac{1}{\lambda}$
*   Y usando el metodo de momentos igualamos el primer momento teórico com el momengto muestral:
  $$\overline{X} = \frac{1}{\lambda} \rightarrow \hat{\lambda}_{MM}=\frac{1}{\overline{X}}$$
* Aplicando la función de verosimilitud ó MLE para la muestra de $\left\{ x_1, \dots, x_n \right\}$ es:
$$L(\lambda)=\prod_{i=1}^{n} \lambda e^{-\lambda x_i} = \lambda^n \exp\left(-\lambda \sum_{i=1}^{n} x_i\right)$$
Y conociendo que el **logaritmo de la verosimilitud^[https://halweb.uc3m.es/esp/Personal/personas/aarribas/esp/docs/estI_tema3.pdf]** es: $$\ell(\lambda) = n \ln \lambda - \lambda \sum_{i=1}^{n} x_i$$
Ahora tomamos el logaritmo de la verosimilitud y lo derivamos respetco a $\lambda$ e igualando a cero:
$$\frac{d\ell}{d\lambda} = \frac{n}{\lambda} - \sum_{i=1}^{n} x_i = 0 \implies \hat{\lambda}_{MLE} = \frac{n}{\sum_{i=1}^{n} x_i} = \frac{1}{ \bar{X}}$$

```{r}
# Configuración inicial
set.seed(123)           # Para reproducibilidad
M <- 10000              # Número de simulaciones
n <- 10                 # Tamaño muestral (n > 2)
lambda_true <- 2        # Valor real de lambda

# Inicializar vectores para almacenar los estimadores
lambda_hat_prop <- numeric(M)  # Estimador propuesto: (n-1)/S_n
lambda_hat_MLE  <- numeric(M)  # Estimador MLE (y de momentos): n/S_n = 1/mean(X)

# Simulación de los experimentos
for(i in 1:M){
  # Generar n tiempos de atención de una exponencial con parámetro lambda_true
  X <- rexp(n, rate = lambda_true)
  S_n <- sum(X)
  
  # Estimador propuesto: (n-1)/S_n
  lambda_hat_prop[i] <- (n - 1) / S_n
  
  # Estimador MLE y de momentos: n/S_n = 1/mean(X)
  lambda_hat_MLE[i] <- n / S_n
}

# Cálculo de sesgo, varianza y ECM para cada estimador
bias_prop <- mean(lambda_hat_prop) - lambda_true
var_prop  <- var(lambda_hat_prop)
mse_prop  <- mean((lambda_hat_prop - lambda_true)^2)

bias_MLE <- mean(lambda_hat_MLE) - lambda_true
var_MLE  <- var(lambda_hat_MLE)
mse_MLE  <- mean((lambda_hat_MLE - lambda_true)^2)

# Crear una tabla con los resultados finales
resultados <- data.frame(
  Estimador = c("Propuesto ((n-1)/S_n)", "MLE (n/S_n = 1/mean(X))"),
  Sesgo     = c(round(bias_prop, 4), round(bias_MLE, 4)),
  Varianza  = c(round(var_prop, 6), round(var_MLE, 6)),
  ECM       = c(round(mse_prop, 6), round(mse_MLE, 6))
)

# Mostrar la tabla de resultados
print(resultados)

# Cargar librerías para gráficos
library(ggplot2)
library(reshape2)

# Crear un data frame con los estimadores para los gráficos
df <- data.frame(`(n-1)/S_n` = lambda_hat_prop, `n/S_n` = lambda_hat_MLE)
df_melt <- melt(df, variable.name = "Estimador", value.name = "Valor")

# Histograma superpuesto de los estimadores
p1 <- ggplot(df_melt, aes(x = Valor, fill = Estimador)) +
  geom_histogram(alpha = 0.5, bins = 50, position = "identity") +
  geom_vline(xintercept = lambda_true, linetype = "dashed", color = "black", size = 1) +
  labs(title = "Distribución de los Estimadores de λ",
       x = "Valor Estimado de λ", y = "Frecuencia") +
  theme_minimal()

# Boxplot comparativo de los estimadores
p2 <- ggplot(df_melt, aes(x = Estimador, y = Valor, fill = Estimador)) +
  geom_boxplot(alpha = 0.7) +
  geom_hline(yintercept = lambda_true, linetype = "dashed", color = "black", size = 1) +
  labs(title = "Boxplot de los Estimadores de λ",
       x = "Estimador", y = "Valor Estimado de λ") +
  theme_minimal()

# Mostrar los gráficos
print(p1)
print(p2)

```

## Conclusiones
*   Tanto en el soporte matemático como el programa en R podemos observar que el estimador $\hat{\lambda}= \frac{n-1}{S_n}$ es **insesgado**.

*   El ECM calculado es $ECM(\hat{\lambda}) = \frac{\lambda²}{n-2}$.

*   Los estimadores calculados de momentos y máxima verosimilitud coinciden ya que $\hat{\lambda}=\frac{1}{\overline{X}}=\frac{n}{S_n}$, con lo cual podemos definir que no importa cual usamos vamos a obtener la misma estimación, en términos generales podemos decir que aplicar el método de momentos es mas fácil de aplicar en situaciones que necesiten rapidez y facilidad, mientras, aplicar el método de máxima verosimilitud cuando se necesite un resultado mas robusto.

# ------------------------------
# NOTAS

## Reglas básicas de Logaritmos:

*   Producto: $log(ab) = log(a) + log(b)$
*   Cociente: $log(\frac{a}{b}) = log(a) - log(b)$
*   Potencia: $log(a^r) = {r}{log(a)}$
*   Logaritmo de 1: $log(1) = 0$
*   Cambio de base: $log_b(a)=\frac{log_c(a)}{log_c(b)^,}$

